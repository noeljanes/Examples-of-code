{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard python numerical analysis imports:\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import signal\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import butter, filtfilt, iirdesign, zpk2tf, freqz\n",
    "import h5py\n",
    "import json\n",
    "import pylab \n",
    "import time\n",
    "\n",
    "# the IPython magic below must be commented out in the .py file, since it doesn't work there.\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "# LIGO-specific readligo.py \n",
    "import readligo as rl\n",
    "\n",
    "# All the pycbc module imports\n",
    "from pycbc.waveform import td_approximants, fd_approximants\n",
    "from pycbc.waveform import get_td_waveform\n",
    "#from pycbc.waveform import generator\n",
    "from pycbc.detector import Detector\n",
    "from pycbc.filter import match\n",
    "from pycbc.psd import aLIGOZeroDetHighPower\n",
    "from pycbc import types, fft, waveform\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "\n",
    "make_plots = 1\n",
    "plottype = \"pdf\"\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "tt = time.time()\n",
    "\n",
    "#-- Default is no event selection; you MUST select one to proceed.\n",
    "eventname = ''\n",
    "eventname = 'GW150914' \n",
    "#eventname = 'GW151226' \n",
    "#eventname = 'LVT151012'\n",
    "#eventname = 'GW170104'\n",
    "\n",
    "# Read the event properties from a local json file\n",
    "fnjson = \"BBH_events_v3.json\"\n",
    "try:\n",
    "    events = json.load(open(fnjson,\"r\"))\n",
    "except IOError:\n",
    "    print(\"Cannot find resource file \"+fnjson)\n",
    "    print(\"You can download it from https://losc.ligo.org/s/events/\"+fnjson)\n",
    "    print(\"Quitting.\")\n",
    "    quit()\n",
    "\n",
    "# did the user select the eventname ?\n",
    "# Prompt to test whether an eventname actually was specified\n",
    "try: \n",
    "    events[eventname]\n",
    "except:\n",
    "    print('You must select an eventname that is in '+fnjson+'! Quitting.')\n",
    "    quit()\n",
    "    \n",
    "# Extract the parameters for the desired event:\n",
    "event = events[eventname]\n",
    "fn_H1 = event['fn_H1']              # File name for H1 data\n",
    "fn_L1 = event['fn_L1']              # File name for L1 data\n",
    "fn_template = event['fn_template']  # File name for template waveform\n",
    "fs = event['fs']                    # Set sampling rate\n",
    "tevent = event['tevent']            # Set approximate event GPS time\n",
    "fband = event['fband']              # frequency band for bandpassing signal\n",
    "\n",
    "try:\n",
    "    # read in data from H1 and L1, if available:\n",
    "    strain_H1, time_H1, chan_dict_H1 = rl.loaddata(fn_H1, 'H1')\n",
    "    strain_L1, time_L1, chan_dict_L1 = rl.loaddata(fn_L1, 'L1')\n",
    "except:\n",
    "    print(\"Cannot find data files!\")\n",
    "    print(\"You can download them from https://losc.ligo.org/s/events/\"+eventname)\n",
    "    print(\"Quitting.\")\n",
    "    quit()\n",
    "    \n",
    "# Both H1 and L1 have the same time vector, so we only need to define one time variable:\n",
    "t = time_H1\n",
    "# The time sample interval (uniformly sampled!)\n",
    "dt = t[1] - t[2]\n",
    "\n",
    "# Plotting a symmetrical period about the event:\n",
    "# index into the strain time series for this time interval:\n",
    "deltat = 5\n",
    "indxt = np.where((t >= tevent-deltat) & (t < tevent+deltat))\n",
    "\n",
    "#POWER SPECTRAL DENSITY CREATION\n",
    "make_psds = 1\n",
    "if make_psds:\n",
    "    # number of sample for the fast fourier transform:\n",
    "    NFFT = 4*fs\n",
    "    Pxx_H1, freqs = mlab.psd(strain_H1, Fs = fs, NFFT = NFFT)\n",
    "    Pxx_L1, freqs = mlab.psd(strain_L1, Fs = fs, NFFT = NFFT)\n",
    "\n",
    "    # We will use interpolations of the ASDs computed above for whitening:\n",
    "    psd_H1 = interp1d(freqs, Pxx_H1)\n",
    "    psd_L1 = interp1d(freqs, Pxx_L1)\n",
    "\n",
    "    # Here is an approximate, smoothed PSD for H1 during O1, with no lines. We'll use it later.    \n",
    "    Pxx = (1.e-22*(18./(0.1+freqs))**2)**2+0.7e-23**2+((freqs/2000.)*4.e-23)**2\n",
    "    psd_smooth = interp1d(freqs, Pxx)\n",
    "\n",
    "# WHITEN THE DATA\n",
    "dt = 1/4096\n",
    "def whiten(strain, interp_psd, dt):\n",
    "    Nt = len(strain)\n",
    "    freqs = np.fft.rfftfreq(Nt, dt)\n",
    "    freqs1 = np.linspace(0,2048.,Nt/2+1)\n",
    "\n",
    "    # whitening: transform to freq domain, divide by asd, then transform back, \n",
    "    # taking care to get normalization right.\n",
    "    hf = np.fft.rfft(strain)\n",
    "    norm = 1./np.sqrt(1./(dt*2))\n",
    "    white_hf = hf / np.sqrt(interp_psd(freqs)) * norm\n",
    "    white_ht = np.fft.irfft(white_hf, n=Nt)\n",
    "    return white_ht\n",
    "\n",
    "whiten_data = 1\n",
    "if whiten_data:\n",
    "    # now whiten the data from H1 and L1, and the template (use H1 PSD):\n",
    "    strain_H1_whiten = whiten(strain_H1,psd_H1,dt)\n",
    "    strain_L1_whiten = whiten(strain_L1,psd_L1,dt)\n",
    "    \n",
    "    # We need to suppress the high frequency noise (no signal!) with some bandpassing:\n",
    "    # Bandpass using a Butterworth filter\n",
    "    bb, ab = butter(4, [fband[0]*2./fs, fband[1]*2./fs], btype='band')\n",
    "    normalization = np.sqrt((fband[1]-fband[0])/(fs/2))\n",
    "    strain_H1_whitenbp = filtfilt(bb, ab, strain_H1_whiten) / normalization\n",
    "    strain_L1_whitenbp = filtfilt(bb, ab, strain_L1_whiten) / normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveform Generation\n",
    "\n",
    "Comment out the section that is wanted below, \n",
    "the order is:\n",
    "1. Exponential Sine-Gaussian distribution\n",
    "2. Gaussian distribution\n",
    "3. Laplace Distribution\n",
    "4. Gumbel Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavetype = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAUS EXP\n",
    "\n",
    "'''\n",
    "wavetype = 'Expgaus'\n",
    "\n",
    "mu = 0 #Offset from centre\n",
    "lamda = 4 # Rate of exponential component\n",
    "sigma = 0.01 # Width constant for the distribution\n",
    "expmult = 125 #Exp amplitude multiplier\n",
    "freqmult = 500 #Sine frequency multiplier\n",
    "sinemult = 5e-24 #Sine amplitude multiplier\n",
    "yexp1 = []\n",
    "\n",
    "xvals = np.linspace(-16,16,4096*32)    # Generates a 32 long x series of 4096Hz\n",
    "\n",
    "\n",
    "# Number of each variable to be generated\n",
    "no_of_lamda=5     \n",
    "no_of_sigma=5     \n",
    "no_of_freq=5  \n",
    "no_of_gamp=5\n",
    "\n",
    "# Extracts a series from 0 to the number of each variable\n",
    "lamda_range,sigma_range,freq_range,gamp_range = range(no_of_lamda),range(no_of_sigma),range(no_of_freq),range(no_of_gamp)\n",
    "\n",
    "# Starting values of each variable\n",
    "lamda_start=4\n",
    "sigma_start=0.01\n",
    "freq_start=250\n",
    "gamp_start=2\n",
    "\n",
    "# Size of intervals in the variables\n",
    "lamda_step = lamda_start / 2\n",
    "sigma_step = sigma_start / 2\n",
    "freq_step = freq_start / 2\n",
    "gamp_step = gamp_start / 2\n",
    "\n",
    "l,s,e,g=[lamda_start + i*lamda_step for i in lamda_range],[sigma_start + i*sigma_step for i in sigma_range],[freq_start + i*freq_step for i in freq_range],[gamp_start + i*gamp_step for i in gamp_range]\n",
    "\n",
    "# Logical indexing to allow for different manipulations of the xvals depending on their values\n",
    "ltzero = xvals < 0   # Creates a list of the xvals that are less than 0\n",
    "gtzero = xvals >= 0  # Creates a list of the xvals that are greater than or equal to 0\n",
    "\n",
    "# Declaring the empty lists\n",
    "values = []\n",
    "yvals = []\n",
    "\n",
    "for a,av in enumerate(l):\n",
    "    for b,bv in enumerate(s):\n",
    "        for c,cv in enumerate(e):\n",
    "            for d,dv in enumerate(g):\n",
    "                y=np.zeros(len(xvals))            \n",
    "                y[ltzero] = expmult*av*np.exp(av*xvals[ltzero])  # Exponential growth for those values that fulfill this criteria  \n",
    "                y[gtzero] = dv*(1/bv*(2*np.pi)**(1/2))*np.exp(-0.5*((xvals[gtzero]-mu)/bv)**2)  # Gaussian for values that fulfill the second criteria          \n",
    "                ysine = sinemult*np.sin(cv*xvals)\n",
    "                y=y*ysine\n",
    "                yvals.append(y)\n",
    "                val = av,bv,cv # Makes a variable with the variables that have been used\n",
    "                values.append(val) # Creates a list of lists\n",
    "\n",
    "#sg_plus_noise = yvals1+noise\n",
    "\n",
    "print('Finished the Exponential Gaussian')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAUS\n",
    "\n",
    "#'''\n",
    "\n",
    "wavetype = 'gaus'\n",
    "\n",
    "mu = 0 #Offset from centre\n",
    "sigma = 0.01 # Width constant for the distribution\n",
    "freqmult = 500 #Sine frequency multiplier\n",
    "sinemult = 5e-24 #Sine amplitude multiplier\n",
    "\n",
    "xvals = np.linspace(-16,16,4096*32)    # Generates a 32 long x series of 4096Hz\n",
    "\n",
    "# Number of each variable to be generated\n",
    "no_of_gamp=6     \n",
    "no_of_sigma=6     \n",
    "no_of_freq=6   \n",
    "\n",
    "# Extracts a series from 0 to the number of each variable\n",
    "gamp_range,sigma_range,freq_range = range(no_of_gamp),range(no_of_sigma),range(no_of_freq)\n",
    "\n",
    "# Starting values of each variable\n",
    "gamp_start=2\n",
    "sigma_start=0.01\n",
    "freq_start=250\n",
    "\n",
    "# Size of intervals in the variables\n",
    "gamp_step = gamp_start / 2\n",
    "sigma_step = sigma_start / 2\n",
    "freq_step = freq_start / 2\n",
    "\n",
    "g,s,e=[gamp_start + i*gamp_step for i in gamp_range],[sigma_start + i*sigma_step for i in sigma_range],[freq_start + i*freq_step for i in freq_range]\n",
    "\n",
    "# Declaring the empty lists\n",
    "values = []\n",
    "yvals = []\n",
    "\n",
    "for a,av in enumerate(g):\n",
    "    for b,bv in enumerate(s):\n",
    "        for c,cv in enumerate(e):\n",
    "            y=np.zeros(len(xvals))  \n",
    "            y = av*(1/bv*(2*np.pi)**(1/2))*np.exp(-0.5*((xvals-mu)/bv)**2)  # Gaussian          \n",
    "            ysine = sinemult*np.sin(cv*xvals)\n",
    "            y=y*ysine\n",
    "            yvals.append(y)\n",
    "            val = av,bv,cv # Makes a variable with the variables that have been used\n",
    "            values.append(val) # Creates a list of lists\n",
    "\n",
    "#sg_plus_noise = yvals1+noise\n",
    "\n",
    "print('Finished gauss')\n",
    "\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LAPLACE\n",
    "\n",
    "#'''\n",
    "\n",
    "wavetype = 'Laplace'\n",
    "\n",
    "mu = 0 #Offset from centre\n",
    "sigma = 0.01 # Width constant for the distribution (sharpness)\n",
    "freqmult = 500 #Sine frequency multiplier\n",
    "sinemult = 5e-24 #Sine amplitude multiplier\n",
    "\n",
    "xvals = np.linspace(-16,16,4096*32)    # Generates a 32 long x series of 4096Hz\n",
    "\n",
    "# Number of each variable to be generated\n",
    "no_of_gamp=6     \n",
    "no_of_sigma=6     \n",
    "no_of_freq=6   \n",
    "\n",
    "# Extracts a series from 0 to the number of each variable\n",
    "gamp_range,sigma_range,freq_range = range(no_of_gamp),range(no_of_sigma),range(no_of_freq)\n",
    "\n",
    "# Starting values of each variable\n",
    "gamp_start=15\n",
    "sigma_start=0.01\n",
    "freq_start=250\n",
    "\n",
    "# Size of intervals in the variables\n",
    "gamp_step = gamp_start / 2\n",
    "sigma_step = sigma_start / 2\n",
    "freq_step = freq_start / 2\n",
    "\n",
    "g,s,e=[gamp_start + i*gamp_step for i in gamp_range],[sigma_start + i*sigma_step for i in sigma_range],[freq_start + i*freq_step for i in freq_range]\n",
    "\n",
    "# Declaring the empty lists\n",
    "values = []\n",
    "yvals = []\n",
    "\n",
    "for a,av in enumerate(g):\n",
    "    for b,bv in enumerate(s):\n",
    "        for c,cv in enumerate(e):\n",
    "            y=np.zeros(len(xvals))  \n",
    "            y = av*(1/(2*bv)*np.exp(-((np.absolute(xvals-mu))/bv))) # Laplace         \n",
    "            ysine = sinemult*np.sin(cv*xvals)\n",
    "            y=y*ysine\n",
    "            yvals.append(y)\n",
    "            val = av,bv,cv # Makes a variable with the variables that have been used\n",
    "            values.append(val) # Creates a list of lists\n",
    "\n",
    "#sg_plus_noise = yvals1+noise\n",
    "\n",
    "print('Finished Laplace')\n",
    "with open('laplace_'+wavetype+'_'+eventname+'.txt','w') as f:\n",
    "    for i in values:\n",
    "        \n",
    "        f.write(str(i) + '\\n')\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GUMBEL\n",
    "'''\n",
    "\n",
    "wavetype = 'Gumbel'\n",
    "\n",
    "mu = 0 #Offset from centre\n",
    "sigma = 0.01 # Width constant for the distribution (sharpness)\n",
    "freqmult = 500 #Sine frequency multiplier\n",
    "sinemult = 5e-24 #Sine amplitude multiplier\n",
    "\n",
    "xvals = np.linspace(-16,16,4096*32)    # Generates a 32 long x series of 4096Hz\n",
    "\n",
    "# Number of each variable to be generated\n",
    "no_of_gamp=6    \n",
    "no_of_sigma=6     \n",
    "no_of_freq=6   \n",
    "\n",
    "# Extracts a series from 0 to the number of each variable\n",
    "gamp_range,sigma_range,freq_range = range(no_of_gamp),range(no_of_sigma),range(no_of_freq)\n",
    "\n",
    "# Starting values of each variable\n",
    "gamp_start=15\n",
    "sigma_start=0.01\n",
    "freq_start=250\n",
    "\n",
    "# Size of intervals in the variables\n",
    "gamp_step = gamp_start / 2\n",
    "sigma_step = sigma_start / 2\n",
    "freq_step = freq_start / 2\n",
    "\n",
    "g,s,e=[gamp_start + i*gamp_step for i in gamp_range],[sigma_start + i*sigma_step for i in sigma_range],[freq_start + i*freq_step for i in freq_range]\n",
    "\n",
    "# Declaring the empty lists\n",
    "values = []\n",
    "yvals = []\n",
    "\n",
    "for a,av in enumerate(g):\n",
    "    for b,bv in enumerate(s):\n",
    "        for c,cv in enumerate(e):\n",
    "            y=np.zeros(len(xvals))  \n",
    "            y = av*((1/bv)*np.exp(-(((-xvals-mu)/bv)+np.exp(-((-xvals-mu)/bv))))) # Gumbel         \n",
    "            ysine = sinemult*np.sin(cv*xvals)\n",
    "            y=y*ysine\n",
    "            yvals.append(y)\n",
    "            val = av,bv,cv # Makes a variable with the variables that have been used\n",
    "            values.append(val) # Creates a list of lists\n",
    "\n",
    "#sg_plus_noise = yvals1+noise\n",
    "\n",
    "print('Finished Gumbel')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wavetype == 0:\n",
    "    print('Need to select a wavetype')\n",
    "else:\n",
    "    print(wavetype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "\n",
    "NFFT = 4*fs\n",
    "psd_window = np.blackman(NFFT)\n",
    "# and a 50% overlap:\n",
    "NOVL = NFFT/2\n",
    "\n",
    "wave_info = []\n",
    "yvals = np.array(yvals)\n",
    "\n",
    "for i in range(len(yvals)):\n",
    "    template = yvals[i] #WAVEFORM FROM LOOP\n",
    "\n",
    "    # the length and sampling rate of the template MUST match that of the data.\n",
    "    datafreq = np.fft.fftfreq(template.size)*fs\n",
    "    df = np.abs(datafreq[1] - datafreq[0])\n",
    "    \n",
    "    # to remove effects at the beginning and end of the data stretch, window the data\n",
    "    # https://en.wikipedia.org/wiki/Window_function#Tukey_window\n",
    "    try:   dwindow = signal.tukey(template.size, alpha=1./8)  # Tukey window preferred, but requires recent scipy version \n",
    "    except: dwindow = signal.blackman(template.size)          # Blackman window OK if Tukey is not available\n",
    "    \n",
    "    # prepare the template fft.\n",
    "    template_fft = np.fft.fft(template*dwindow) / fs\n",
    "    \n",
    "    # loop over the detectors\n",
    "    dets = ['H1', 'L1']\n",
    "    for det in dets:\n",
    "    \n",
    "        if det is 'L1': data = strain_L1.copy()\n",
    "        else:           data = strain_H1.copy()\n",
    "    \n",
    "        # -- Calculate the PSD of the data.  Also use an overlap, and window:\n",
    "        data_psd, freqs = mlab.psd(data, Fs = fs, NFFT = NFFT, window=psd_window, noverlap=NOVL)\n",
    "    \n",
    "        # Take the Fourier Transform (FFT) of the data and the template (with dwindow)\n",
    "        data_fft = np.fft.fft(data*dwindow) / fs\n",
    "    \n",
    "        # -- Interpolate to get the PSD values at the needed frequencies\n",
    "        power_vec = np.interp(np.abs(datafreq), freqs, data_psd)\n",
    "    \n",
    "        # -- Calculate the matched filter output in the time domain:\n",
    "        # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n",
    "        # Taking the Inverse Fourier Transform (IFFT) of the filter output puts it back in the time domain,\n",
    "        # so the result will be plotted as a function of time off-set between the template and the data:\n",
    "        optimal = data_fft * template_fft.conjugate() / power_vec\n",
    "        optimal_time = 2*np.fft.ifft(optimal)*fs\n",
    "    \n",
    "        # -- Normalize the matched filter output:\n",
    "        # Normalize the matched filter output so that we expect a value of 1 at times of just noise.\n",
    "        # Then, the peak of the matched filter output will tell us the signal-to-noise ratio (SNR) of the signal.\n",
    "        sigmasq = 1*(template_fft * template_fft.conjugate() / power_vec).sum() * df\n",
    "        sigma = np.sqrt(np.abs(sigmasq))\n",
    "        SNR_complex = optimal_time/sigma\n",
    "    \n",
    "        # shift the SNR vector by the template length so that the peak is at the END of the template\n",
    "        peaksample = int(data.size / 2)  # location of peak in the template\n",
    "        SNR_complex = np.roll(SNR_complex,peaksample)\n",
    "        SNR = abs(SNR_complex)\n",
    "    \n",
    "        # find the time and SNR value at maximum:\n",
    "        indmax = np.argmax(SNR)\n",
    "        timemax = t[indmax]\n",
    "        SNRmax = SNR[indmax]\n",
    "    \n",
    "        # Calculate the \"effective distance\" (see FINDCHIRP paper for definition)\n",
    "        # d_eff = (8. / SNRmax)*D_thresh\n",
    "        d_eff = sigma / SNRmax\n",
    "        # -- Calculate optimal horizon distnace\n",
    "        horizon = sigma/8\n",
    "    \n",
    "        # Extract time offset and phase at peak\n",
    "        phase = np.angle(SNR_complex[indmax])\n",
    "        offset = (indmax-peaksample)\n",
    "    \n",
    "        # apply time offset, phase, and d_eff to template \n",
    "        template_phaseshifted = np.real(template*np.exp(1j*phase))    # phase shift the template\n",
    "        template_rolled = np.roll(template_phaseshifted,offset) / d_eff  # Apply time offset and scale amplitude\n",
    "        \n",
    "        # Whiten and band-pass the template for plotting\n",
    "        template_whitened = whiten(template_rolled,interp1d(freqs, data_psd),dt)  # whiten the template\n",
    "        template_match = filtfilt(bb, ab, template_whitened) / normalization # Band-pass the template        \n",
    "       \n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1':\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "        else:\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "                   \n",
    "        # Calculating the correlation of the template and the data\n",
    "        template_match = template_match[60000:70000]\n",
    "        strain_whitenbp = strain_whitenbp[60000:70000]\n",
    "        corre = np.correlate(strain_whitenbp, template_match)   # Non-normalised correlation function\n",
    "        denom = np.sqrt(sum(strain_whitenbp**2)*sum(template_match**2))   # Denominator for scaling the correlation coefficient\n",
    "        normcor = corre/denom  # Normalises the correlation coefficient\n",
    "\n",
    "        #print('Normalised correlation coefficient',normcor)\n",
    "\n",
    "        # Calculating a value for the residual using abosulte values\n",
    "\n",
    "        resid = strain_whitenbp - template_match   # Creates the residual data\n",
    "        absresid = []   \n",
    "        for j in resid:\n",
    "            absresid.append(abs(j))   # Takes the absolute value of the ith number and appends it to the empty list\n",
    "        residco = sum(absresid)   # Sums up the absolute values of the residual plot to give a metric for the quality of the match\n",
    "        \n",
    "        #print('Sum of the absolute values of the residual', residco)\n",
    "        normcor = float(normcor)\n",
    "        wave_info.append([i,det,normcor,residco])\n",
    "        \n",
    "elapsed = time.time() - t2\n",
    "print('finished',elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wave_info_full_'+wavetype+'_'+eventname+'.txt','w') as f:\n",
    "    for i in wave_info:\n",
    "        \n",
    "        f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmax=wave_info[0]\n",
    "residmax=wave_info[0]\n",
    "corrmin=wave_info[0]\n",
    "residmin=wave_info[0]\n",
    "\n",
    "\n",
    "for i in wave_info:\n",
    "    corr = i[2]\n",
    "    resid = i[3]\n",
    "    \n",
    "    if corr > corrmax[2]: # This is the best correlation, the closer to 1 the better\n",
    "        corrmax = i\n",
    "    \n",
    "    if corr < corrmin[2]: # This is the worst correlation\n",
    "        corrmin = i\n",
    "\n",
    "        \n",
    "    if resid > residmax[3]: # This is the worst residual\n",
    "        residmax = i\n",
    "\n",
    "    \n",
    "    if resid < residmin[3]: # This is the best residual, the closer to 0 the better\n",
    "        residmin = i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plots = 1\n",
    "\n",
    "print(corrmax)\n",
    "template = yvals[corrmax[0]] #WAVEFORM FROM LOOP\n",
    "\n",
    "# the length and sampling rate of the template MUST match that of the data.\n",
    "datafreq = np.fft.fftfreq(template.size)*fs\n",
    "df = np.abs(datafreq[1] - datafreq[0])\n",
    "\n",
    "# to remove effects at the beginning and end of the data stretch, window the data\n",
    "# https://en.wikipedia.org/wiki/Window_function#Tukey_window\n",
    "try:   dwindow = signal.tukey(template.size, alpha=1./8)  # Tukey window preferred, but requires recent scipy version \n",
    "except: dwindow = signal.blackman(template.size)          # Blackman window OK if Tukey is not available\n",
    "\n",
    "# prepare the template fft.\n",
    "template_fft = np.fft.fft(template*dwindow) / fs\n",
    "\n",
    "# loop over the detectors\n",
    "dets = ['H1', 'L1']\n",
    "for det in dets:\n",
    "\n",
    "    if det is 'L1': data = strain_L1.copy()\n",
    "    else:           data = strain_H1.copy()\n",
    "\n",
    "    # -- Calculate the PSD of the data.  Also use an overlap, and window:\n",
    "    data_psd, freqs = mlab.psd(data, Fs = fs, NFFT = NFFT, window=psd_window, noverlap=NOVL)\n",
    "\n",
    "    # Take the Fourier Transform (FFT) of the data and the template (with dwindow)\n",
    "    data_fft = np.fft.fft(data*dwindow) / fs\n",
    "\n",
    "    # -- Interpolate to get the PSD values at the needed frequencies\n",
    "    power_vec = np.interp(np.abs(datafreq), freqs, data_psd)\n",
    "\n",
    "    # -- Calculate the matched filter output in the time domain:\n",
    "    # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n",
    "    # Taking the Inverse Fourier Transform (IFFT) of the filter output puts it back in the time domain,\n",
    "    # so the result will be plotted as a function of time off-set between the template and the data:\n",
    "    optimal = data_fft * template_fft.conjugate() / power_vec\n",
    "    optimal_time = 2*np.fft.ifft(optimal)*fs\n",
    "\n",
    "    # -- Normalize the matched filter output:\n",
    "    # Normalize the matched filter output so that we expect a value of 1 at times of just noise.\n",
    "    # Then, the peak of the matched filter output will tell us the signal-to-noise ratio (SNR) of the signal.\n",
    "    sigmasq = 1*(template_fft * template_fft.conjugate() / power_vec).sum() * df\n",
    "    sigma = np.sqrt(np.abs(sigmasq))\n",
    "    SNR_complex = optimal_time/sigma\n",
    "\n",
    "    # shift the SNR vector by the template length so that the peak is at the END of the template\n",
    "    peaksample = int(data.size / 2)  # location of peak in the template\n",
    "    SNR_complex = np.roll(SNR_complex,peaksample)\n",
    "    SNR = abs(SNR_complex)\n",
    "\n",
    "    # find the time and SNR value at maximum:\n",
    "    indmax = np.argmax(SNR)\n",
    "    timemax = t[indmax]\n",
    "    SNRmax = SNR[indmax]\n",
    "\n",
    "    # Calculate the \"effective distance\" (see FINDCHIRP paper for definition)\n",
    "    # d_eff = (8. / SNRmax)*D_thresh\n",
    "    d_eff = sigma / SNRmax\n",
    "    # -- Calculate optimal horizon distnace\n",
    "    horizon = sigma/8\n",
    "\n",
    "    # Extract time offset and phase at peak\n",
    "    phase = np.angle(SNR_complex[indmax])\n",
    "    offset = (indmax-peaksample)\n",
    "\n",
    "    # apply time offset, phase, and d_eff to template \n",
    "    template_phaseshifted = np.real(template*np.exp(1j*phase))    # phase shift the template\n",
    "    template_rolled = np.roll(template_phaseshifted,offset) / d_eff  # Apply time offset and scale amplitude\n",
    "    \n",
    "    # Whiten and band-pass the template for plotting\n",
    "    template_whitened = whiten(template_rolled,interp1d(freqs, data_psd),dt)  # whiten the template\n",
    "    template_match = filtfilt(bb, ab, template_whitened) / normalization # Band-pass the template\n",
    "    \n",
    "    if make_plots:\n",
    "\n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "        # -- Plot the result\n",
    "        plt.figure(figsize=(16,8))\n",
    "        '''\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(t-timemax, SNR, pcolor,label=det+' SNR(t)')\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',corrmax[2]))\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',corrmax[3]))\n",
    "        #plt.ylim([0,25.])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('SNR')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' matched filter SNR around event for waveform no.'+str(corrmax[0]))\n",
    "      \n",
    "        plt.subplot(2,1,2)\n",
    "        '''\n",
    "        plt.plot(t-tevent,strain_whitenbp,pcolor,label=det+' whitened h(t)')\n",
    "        plt.plot(t-tevent,template_match,'k',label='Template(t)')\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',corrmax[2]))\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',corrmax[3]))\n",
    "        plt.ylim([-10,10])\n",
    "        plt.xlim([-0.15,0.05])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('whitened strain (units of noise stdev)')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' whitened data around event for waveform no.'+str(corrmax[0]))\n",
    "        plt.savefig(eventname+\"_\"+det+\"_\"+wavetype+\"_maxcorr.\"+plottype, bbox_inches='tight')\n",
    "        \n",
    "\n",
    "print(corrmin)\n",
    "template = yvals[corrmin[0]] #WAVEFORM FROM LOOP\n",
    "\n",
    "# the length and sampling rate of the template MUST match that of the data.\n",
    "datafreq = np.fft.fftfreq(template.size)*fs\n",
    "df = np.abs(datafreq[1] - datafreq[0])\n",
    "\n",
    "# to remove effects at the beginning and end of the data stretch, window the data\n",
    "# https://en.wikipedia.org/wiki/Window_function#Tukey_window\n",
    "try:   dwindow = signal.tukey(template.size, alpha=1./8)  # Tukey window preferred, but requires recent scipy version \n",
    "except: dwindow = signal.blackman(template.size)          # Blackman window OK if Tukey is not available\n",
    "\n",
    "# prepare the template fft.\n",
    "template_fft = np.fft.fft(template*dwindow) / fs\n",
    "\n",
    "# loop over the detectors\n",
    "dets = ['H1', 'L1']\n",
    "for det in dets:\n",
    "\n",
    "    if det is 'L1': data = strain_L1.copy()\n",
    "    else:           data = strain_H1.copy()\n",
    "\n",
    "    # -- Calculate the PSD of the data.  Also use an overlap, and window:\n",
    "    data_psd, freqs = mlab.psd(data, Fs = fs, NFFT = NFFT, window=psd_window, noverlap=NOVL)\n",
    "\n",
    "    # Take the Fourier Transform (FFT) of the data and the template (with dwindow)\n",
    "    data_fft = np.fft.fft(data*dwindow) / fs\n",
    "\n",
    "    # -- Interpolate to get the PSD values at the needed frequencies\n",
    "    power_vec = np.interp(np.abs(datafreq), freqs, data_psd)\n",
    "\n",
    "    # -- Calculate the matched filter output in the time domain:\n",
    "    # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n",
    "    # Taking the Inverse Fourier Transform (IFFT) of the filter output puts it back in the time domain,\n",
    "    # so the result will be plotted as a function of time off-set between the template and the data:\n",
    "    optimal = data_fft * template_fft.conjugate() / power_vec\n",
    "    optimal_time = 2*np.fft.ifft(optimal)*fs\n",
    "\n",
    "    # -- Normalize the matched filter output:\n",
    "    # Normalize the matched filter output so that we expect a value of 1 at times of just noise.\n",
    "    # Then, the peak of the matched filter output will tell us the signal-to-noise ratio (SNR) of the signal.\n",
    "    sigmasq = 1*(template_fft * template_fft.conjugate() / power_vec).sum() * df\n",
    "    sigma = np.sqrt(np.abs(sigmasq))\n",
    "    SNR_complex = optimal_time/sigma\n",
    "\n",
    "    # shift the SNR vector by the template length so that the peak is at the END of the template\n",
    "    peaksample = int(data.size / 2)  # location of peak in the template\n",
    "    SNR_complex = np.roll(SNR_complex,peaksample)\n",
    "    SNR = abs(SNR_complex)\n",
    "\n",
    "    # find the time and SNR value at maximum:\n",
    "    indmax = np.argmax(SNR)\n",
    "    timemax = t[indmax]\n",
    "    SNRmax = SNR[indmax]\n",
    "\n",
    "    # Calculate the \"effective distance\" (see FINDCHIRP paper for definition)\n",
    "    # d_eff = (8. / SNRmax)*D_thresh\n",
    "    d_eff = sigma / SNRmax\n",
    "    # -- Calculate optimal horizon distnace\n",
    "    horizon = sigma/8\n",
    "\n",
    "    # Extract time offset and phase at peak\n",
    "    phase = np.angle(SNR_complex[indmax])\n",
    "    offset = (indmax-peaksample)\n",
    "\n",
    "    # apply time offset, phase, and d_eff to template \n",
    "    template_phaseshifted = np.real(template*np.exp(1j*phase))    # phase shift the template\n",
    "    template_rolled = np.roll(template_phaseshifted,offset) / d_eff  # Apply time offset and scale amplitude\n",
    "    \n",
    "    # Whiten and band-pass the template for plotting\n",
    "    template_whitened = whiten(template_rolled,interp1d(freqs, data_psd),dt)  # whiten the template\n",
    "    template_match = filtfilt(bb, ab, template_whitened) / normalization # Band-pass the template\n",
    "    \n",
    "    if make_plots:\n",
    "\n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "\n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "        # -- Plot the result\n",
    "        plt.figure(figsize=(16,8))\n",
    "        '''\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(t-timemax, SNR, pcolor,label=det+' SNR(t)')\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',corrmin[2]))\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',corrmin[3]))\n",
    "        #plt.ylim([0,25.])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('SNR')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' matched filter SNR around event for waveform no.'+str(corrmin[0]))\n",
    "      \n",
    "        plt.subplot(2,1,2)\n",
    "        '''\n",
    "        plt.plot(t-tevent,strain_whitenbp,pcolor,label=det+' whitened h(t)')\n",
    "        plt.plot(t-tevent,template_match,'k',label='Template(t)')\n",
    "       # plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',corrmin[2]))\n",
    "       # plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',corrmin[3]))\n",
    "        plt.ylim([-10,10])\n",
    "        plt.xlim([-0.15,0.05])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('whitened strain (units of noise stdev)')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' whitened data around event for waveform no.'+str(corrmin[0]))\n",
    "        plt.savefig(eventname+\"_\"+det+\"_\"+wavetype+\"_mincorr.\"+plottype, bbox_inches='tight')\n",
    "        \n",
    "print(residmax)\n",
    "template = yvals[residmax[0]] #WAVEFORM FROM LOOP\n",
    "\n",
    "# the length and sampling rate of the template MUST match that of the data.\n",
    "datafreq = np.fft.fftfreq(template.size)*fs\n",
    "df = np.abs(datafreq[1] - datafreq[0])\n",
    "\n",
    "# to remove effects at the beginning and end of the data stretch, window the data\n",
    "# https://en.wikipedia.org/wiki/Window_function#Tukey_window\n",
    "try:   dwindow = signal.tukey(template.size, alpha=1./8)  # Tukey window preferred, but requires recent scipy version \n",
    "except: dwindow = signal.blackman(template.size)          # Blackman window OK if Tukey is not available\n",
    "\n",
    "# prepare the template fft.\n",
    "template_fft = np.fft.fft(template*dwindow) / fs\n",
    "\n",
    "# loop over the detectors\n",
    "dets = ['H1', 'L1']\n",
    "for det in dets:\n",
    "\n",
    "    if det is 'L1': data = strain_L1.copy()\n",
    "    else:           data = strain_H1.copy()\n",
    "\n",
    "    # -- Calculate the PSD of the data.  Also use an overlap, and window:\n",
    "    data_psd, freqs = mlab.psd(data, Fs = fs, NFFT = NFFT, window=psd_window, noverlap=NOVL)\n",
    "\n",
    "    # Take the Fourier Transform (FFT) of the data and the template (with dwindow)\n",
    "    data_fft = np.fft.fft(data*dwindow) / fs\n",
    "\n",
    "    # -- Interpolate to get the PSD values at the needed frequencies\n",
    "    power_vec = np.interp(np.abs(datafreq), freqs, data_psd)\n",
    "\n",
    "    # -- Calculate the matched filter output in the time domain:\n",
    "    # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n",
    "    # Taking the Inverse Fourier Transform (IFFT) of the filter output puts it back in the time domain,\n",
    "    # so the result will be plotted as a function of time off-set between the template and the data:\n",
    "    optimal = data_fft * template_fft.conjugate() / power_vec\n",
    "    optimal_time = 2*np.fft.ifft(optimal)*fs\n",
    "\n",
    "    # -- Normalize the matched filter output:\n",
    "    # Normalize the matched filter output so that we expect a value of 1 at times of just noise.\n",
    "    # Then, the peak of the matched filter output will tell us the signal-to-noise ratio (SNR) of the signal.\n",
    "    sigmasq = 1*(template_fft * template_fft.conjugate() / power_vec).sum() * df\n",
    "    sigma = np.sqrt(np.abs(sigmasq))\n",
    "    SNR_complex = optimal_time/sigma\n",
    "\n",
    "    # shift the SNR vector by the template length so that the peak is at the END of the template\n",
    "    peaksample = int(data.size / 2)  # location of peak in the template\n",
    "    SNR_complex = np.roll(SNR_complex,peaksample)\n",
    "    SNR = abs(SNR_complex)\n",
    "\n",
    "    # find the time and SNR value at maximum:\n",
    "    indmax = np.argmax(SNR)\n",
    "    timemax = t[indmax]\n",
    "    SNRmax = SNR[indmax]\n",
    "\n",
    "    # Calculate the \"effective distance\" (see FINDCHIRP paper for definition)\n",
    "    # d_eff = (8. / SNRmax)*D_thresh\n",
    "    d_eff = sigma / SNRmax\n",
    "    # -- Calculate optimal horizon distnace\n",
    "    horizon = sigma/8\n",
    "\n",
    "    # Extract time offset and phase at peak\n",
    "    phase = np.angle(SNR_complex[indmax])\n",
    "    offset = (indmax-peaksample)\n",
    "\n",
    "    # apply time offset, phase, and d_eff to template \n",
    "    template_phaseshifted = np.real(template*np.exp(1j*phase))    # phase shift the template\n",
    "    template_rolled = np.roll(template_phaseshifted,offset) / d_eff  # Apply time offset and scale amplitude\n",
    "    \n",
    "    # Whiten and band-pass the template for plotting\n",
    "    template_whitened = whiten(template_rolled,interp1d(freqs, data_psd),dt)  # whiten the template\n",
    "    template_match = filtfilt(bb, ab, template_whitened) / normalization # Band-pass the template\n",
    "    \n",
    "    if make_plots:\n",
    "\n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "        \n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "        # -- Plot the result\n",
    "        plt.figure(figsize=(16,8))\n",
    "        '''        plt.subplot(2,1,1)\n",
    "        plt.plot(t-timemax, SNR, pcolor,label=det+' SNR(t)')\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',residmax[2]))\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',residmax[3]))\n",
    "        #plt.ylim([0,25.])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('SNR')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' matched filter SNR around event for waveform no.'+str(residmax[0]))\n",
    "      \n",
    "        plt.subplot(2,1,2)\n",
    "        '''\n",
    "        plt.plot(t-tevent,strain_whitenbp,pcolor,label=det+' whitened h(t)')\n",
    "        plt.plot(t-tevent,template_match,'k',label='Template(t)')\n",
    "     #   plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',residmax[2]))\n",
    "      #  plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',residmax[3]))\n",
    "        plt.ylim([-10,10])\n",
    "        plt.xlim([-0.15,0.05])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('whitened strain (units of noise stdev)')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' whitened data around event for waveform no.'+str(residmax[0]))\n",
    "        plt.savefig(eventname+\"_\"+det+\"_\"+wavetype+\"_maxresid.\"+plottype, bbox_inches='tight')\n",
    "        \n",
    "        \n",
    "print(residmin)\n",
    "template = yvals[residmin[0]] #WAVEFORM FROM LOOP\n",
    "\n",
    "# the length and sampling rate of the template MUST match that of the data.\n",
    "datafreq = np.fft.fftfreq(template.size)*fs\n",
    "df = np.abs(datafreq[1] - datafreq[0])\n",
    "\n",
    "# to remove effects at the beginning and end of the data stretch, window the data\n",
    "# https://en.wikipedia.org/wiki/Window_function#Tukey_window\n",
    "try:   dwindow = signal.tukey(template.size, alpha=1./8)  # Tukey window preferred, but requires recent scipy version \n",
    "except: dwindow = signal.blackman(template.size)          # Blackman window OK if Tukey is not available\n",
    "\n",
    "# prepare the template fft.\n",
    "template_fft = np.fft.fft(template*dwindow) / fs\n",
    "\n",
    "# loop over the detectors\n",
    "dets = ['H1', 'L1']\n",
    "for det in dets:\n",
    "\n",
    "    if det is 'L1': data = strain_L1.copy()\n",
    "    else:           data = strain_H1.copy()\n",
    "\n",
    "    # -- Calculate the PSD of the data.  Also use an overlap, and window:\n",
    "    data_psd, freqs = mlab.psd(data, Fs = fs, NFFT = NFFT, window=psd_window, noverlap=NOVL)\n",
    "\n",
    "    # Take the Fourier Transform (FFT) of the data and the template (with dwindow)\n",
    "    data_fft = np.fft.fft(data*dwindow) / fs\n",
    "\n",
    "    # -- Interpolate to get the PSD values at the needed frequencies\n",
    "    power_vec = np.interp(np.abs(datafreq), freqs, data_psd)\n",
    "\n",
    "    # -- Calculate the matched filter output in the time domain:\n",
    "    # Multiply the Fourier Space template and data, and divide by the noise power in each frequency bin.\n",
    "    # Taking the Inverse Fourier Transform (IFFT) of the filter output puts it back in the time domain,\n",
    "    # so the result will be plotted as a function of time off-set between the template and the data:\n",
    "    optimal = data_fft * template_fft.conjugate() / power_vec\n",
    "    optimal_time = 2*np.fft.ifft(optimal)*fs\n",
    "\n",
    "    # -- Normalize the matched filter output:\n",
    "    # Normalize the matched filter output so that we expect a value of 1 at times of just noise.\n",
    "    # Then, the peak of the matched filter output will tell us the signal-to-noise ratio (SNR) of the signal.\n",
    "    sigmasq = 1*(template_fft * template_fft.conjugate() / power_vec).sum() * df\n",
    "    sigma = np.sqrt(np.abs(sigmasq))\n",
    "    SNR_complex = optimal_time/sigma\n",
    "\n",
    "    # shift the SNR vector by the template length so that the peak is at the END of the template\n",
    "    peaksample = int(data.size / 2)  # location of peak in the template\n",
    "    SNR_complex = np.roll(SNR_complex,peaksample)\n",
    "    SNR = abs(SNR_complex)\n",
    "\n",
    "    # find the time and SNR value at maximum:\n",
    "    indmax = np.argmax(SNR)\n",
    "    timemax = t[indmax]\n",
    "    SNRmax = SNR[indmax]\n",
    "\n",
    "    # Calculate the \"effective distance\" (see FINDCHIRP paper for definition)\n",
    "    # d_eff = (8. / SNRmax)*D_thresh\n",
    "    d_eff = sigma / SNRmax\n",
    "    # -- Calculate optimal horizon distnace\n",
    "    horizon = sigma/8\n",
    "\n",
    "    # Extract time offset and phase at peak\n",
    "    phase = np.angle(SNR_complex[indmax])\n",
    "    offset = (indmax-peaksample)\n",
    "\n",
    "    # apply time offset, phase, and d_eff to template \n",
    "    template_phaseshifted = np.real(template*np.exp(1j*phase))    # phase shift the template\n",
    "    template_rolled = np.roll(template_phaseshifted,offset) / d_eff  # Apply time offset and scale amplitude\n",
    "    \n",
    "    # Whiten and band-pass the template for plotting\n",
    "    template_whitened = whiten(template_rolled,interp1d(freqs, data_psd),dt)  # whiten the template\n",
    "    template_match = filtfilt(bb, ab, template_whitened) / normalization # Band-pass the template\n",
    "    \n",
    "    if make_plots:\n",
    "\n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "       \n",
    "        # plotting changes for the detectors:\n",
    "        if det is 'L1': \n",
    "            pcolor='g'\n",
    "            strain_whitenbp = strain_L1_whitenbp\n",
    "            template_L1 = template_match.copy()\n",
    "        else:\n",
    "            pcolor='r'\n",
    "            strain_whitenbp = strain_H1_whitenbp\n",
    "            template_H1 = template_match.copy()\n",
    "\n",
    "        # -- Plot the result\n",
    "        plt.figure(figsize=(16,8))\n",
    "        '''\n",
    "        plt.subplot(2,1,1)\n",
    "        plt.plot(t-timemax, SNR, pcolor,label=det+' SNR(t)')\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',residmin[2]))\n",
    "        #plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',residmin[3]))\n",
    "        #plt.ylim([0,25.])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('SNR')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' matched filter SNR around event for waveform no.'+str(residmin[0]))\n",
    "      \n",
    "        plt.subplot(2,1,2)\n",
    "        '''\n",
    "        plt.plot(t-tevent,strain_whitenbp,pcolor,label=det+' whitened h(t)')\n",
    "        plt.plot(t-tevent,template_match,'k',label='Template(t)')\n",
    "       # plt.plot(np.NaN, np.NaN, '-', color='none',label=('Normalised correlation',residmin[2]))\n",
    "       # plt.plot(np.NaN, np.NaN, '-', color='none',label=('Residual sum',residmin[3]))\n",
    "        plt.ylim([-10,10])\n",
    "        plt.xlim([-0.15,0.05])\n",
    "        plt.grid('on')\n",
    "        plt.ylabel('whitened strain (units of noise stdev)')\n",
    "        plt.legend(loc='upper left',fontsize = 'x-small')\n",
    "        #plt.title(det+' whitened data around event for waveform no.'+str(residmin[0]))\n",
    "        plt.savefig(eventname+\"_\"+det+\"_\"+wavetype+\"_minresid.\"+plottype, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "info = [corrmax,corrmin,residmax,residmin]\n",
    "header = ['corrmax','corrmin','residmax','residmin']\n",
    "\n",
    "counter = 0\n",
    "with open('wave_info_'+wavetype+'_'+eventname+'.txt','w') as f:\n",
    "    for i in info:\n",
    "        \n",
    "        f.write(header[counter] + '\\n' + str(i) + '\\n')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totelapsed = time.time()-tt\n",
    "print('Total time taken', totelapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3: special - LIGO",
   "language": "python",
   "name": "gw-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
